{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import data\n",
    "from math import inf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For how the data.Poems works, read the readme, or look at the N-Gram-Basic jupyter notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.poems is ready!\n"
     ]
    }
   ],
   "source": [
    "poems = data.Poems(\".\\\\Poem Data\\\\PoetryFoundationData.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I will convert all the poems, in word, to poems with their respective syllable counts!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding Syllables Count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the Syllables dictionary, this was downloaded from CMU, here's the [link](http://svn.code.sf.net/p/cmusphinx/code/trunk/cmudict/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>syllable_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A(1)</td>\n",
       "      <td>EY1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A'S</td>\n",
       "      <td>EY1 Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A.</td>\n",
       "      <td>EY1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A.'S</td>\n",
       "      <td>EY1 Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A.S</td>\n",
       "      <td>EY1 Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  words syllable_count\n",
       "0  A(1)            EY1\n",
       "1   A'S          EY1 Z\n",
       "2    A.            EY1\n",
       "3  A.'S          EY1 Z\n",
       "4   A.S          EY1 Z"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syllables = pd.read_csv(\".\\\\Syllable Data\\\\syllable_dict.txt\",\"  \", engine=\"python\")\n",
    "syllables = syllables.rename(columns = {\"A\":\"words\",\"AH0\":\"syllable_count\"})\n",
    "syllables.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please read the documentation provided by CMU to understand the meaning of what the syllable_count column represents.<br>\n",
    "For our purposes, \n",
    "<li> 0 = No-stress syllable\n",
    "<li> 1 = Primary stress syllable\n",
    "<li> 2 = Secondary stress syllable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the above DataFrame to build a Python dictionary of the Syllables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_syllables(string):\n",
    "    count = 0\n",
    "    for ch in string:\n",
    "        if(ch in \"012\"): # If a syllable is detected\n",
    "            count=count+1\n",
    "    return(count)\n",
    "\n",
    "syllables.syllable_count = (syllables.syllable_count.map(number_of_syllables))\n",
    "syllable_dict = dict([(word, syllable)for word,syllable in zip(syllables.words,syllables.syllable_count)])\n",
    "#Some other basic additions to it manually\n",
    "syllable_dict[\"A\"] = 1\n",
    "syllable_dict[\"NEWLINE\"] = \"NEWLINE\"\n",
    "syllable_dict[\",\"] = \"punc\"\n",
    "syllable_dict[\".\"] = \"punc\"\n",
    "#syllable_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tagging the poems with the syllables dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tags the words present in the dictionary. Although, there is a probem. <br>\n",
    "It is quite possible that every word present in the poems might not be in the dictionary. <br>\n",
    "For such purposes, we also want to find the count of the number of syllables of all such words. We start by returning all such words!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns all the words that were not present in the dictionary\n",
    "def tag_syllables(poem, untagged):\n",
    "    tagged_poem = []\n",
    "    for token in poem:\n",
    "        if(token in syllable_dict):\n",
    "            tag = syllable_dict[token]\n",
    "            tagged_poem = tagged_poem + [(token,tag)] \n",
    "        else:\n",
    "            untagged += [token]\n",
    "    return(tagged_poem, untagged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The missing words problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63016"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_in_dict = []\n",
    "for poem in poems.poems:\n",
    "    a,not_in_dict = tag_syllables(poem,not_in_dict)\n",
    "#set(not_in_dict)\n",
    "len(set(not_in_dict))\n",
    "#list(set(not_in_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using CMU Building to build more dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We write all the missing words to a file, which we then upload to CMU marker tool. Then we will have syllable counts for all again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "File_object = open(\"missing_words.txt\",\"w\")\n",
    "c = []\n",
    "for word in (list(set(untagged))):\n",
    "    try:\n",
    "        #print(word)\n",
    "        File_object.writelines(word+\"\\n\")\n",
    "    except Exception as e:\n",
    "        c = c+[word]\n",
    "File_object.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the dictionaries to find the counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I had to iterate the previous process 4 times! Hence, 4 sepearate dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>syllable_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>YNOUGH</td>\n",
       "      <td>Y N UW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AGATHAS</td>\n",
       "      <td>AE G AH TH AH Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ARETO</td>\n",
       "      <td>AE R AH T OW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UNSOUNDED</td>\n",
       "      <td>AH N S AW N D IH D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NIGHTIESMALL</td>\n",
       "      <td>N AY T AY S M AO L</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          words      syllable_count\n",
       "0        YNOUGH              Y N UW\n",
       "1       AGATHAS     AE G AH TH AH Z\n",
       "2         ARETO        AE R AH T OW\n",
       "3     UNSOUNDED  AH N S AW N D IH D\n",
       "4  NIGHTIESMALL  N AY T AY S M AO L"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict1 = pd.read_csv(\".\\\\Syllable Data\\\\dict1.txt\",\"\\t\", engine=\"python\")\n",
    "dict1 = dict1.rename(columns={\"SCYTHING\":\"words\",\"S IH DH AH NG\":\"syllable_count\"})\n",
    "dict2 = pd.read_csv(\".\\\\Syllable Data\\\\dict2.txt\",\"\\t\", engine=\"python\")\n",
    "dict2 = dict2.rename(columns={\"TREATERS/\":\"words\",\"T R IY T ER Z\":\"syllable_count\"})\n",
    "dict3 = pd.read_csv(\".\\\\Syllable Data\\\\dict3.txt\",\"\\t\", engine=\"python\")\n",
    "dict3 = dict3.rename(columns={\"NOMMO\":\"words\",\"N AA M OW\":\"syllable_count\"})\n",
    "dict4 = pd.read_csv(\".\\\\Syllable Data\\\\dict4.txt\",\"\\t\", engine=\"python\")\n",
    "dict4 = dict4.rename(columns={\"UNINFORMD\":\"words\",\"Y UW N AH N F AO R M D\":\"syllable_count\"})\n",
    "\n",
    "dictionary = ((dict1.append(dict2)).append(dict3)).append(dict4)\n",
    "dictionary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.to_csv(\"new_words_syllables.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the phones to identify syllables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AE', 'AH', 'AO', 'AW', 'AY', 'EH', 'ER', 'EY', 'IH', 'IY', 'OW', 'OY', 'UH', 'UW', 'AA']\n"
     ]
    }
   ],
   "source": [
    "phones = pd.read_csv(\".\\\\Syllable Data\\\\phones.txt\",\"\\t\", engine=\"python\")\n",
    "phones = phones.rename(columns={\"AA\":\"symbol\",\"vowel\":\"meaning\"})\n",
    "phones = phones[phones[\"meaning\"]==\"vowel\"]\n",
    "vowels = list(phones.symbol)\n",
    "vowels = vowels + [\"AA\"]\n",
    "print(vowels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def syllables_count(string):\n",
    "    l = str(string).split(\" \")\n",
    "    count = 0\n",
    "    for a in l:\n",
    "        if(a in vowels):\n",
    "            count+=1\n",
    "    return count\n",
    "dictionary.syllable_count = dictionary.syllable_count.map(syllables_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_database = syllables.append(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "syllable_dict = dict([(word, syllable)for word,syllable in zip(dict_database.words,dict_database.syllable_count)])\n",
    "#Some other basic additions to it manually\n",
    "syllable_dict[\"A\"] = 1\n",
    "syllable_dict[\"NEWLINE\"] = \"NEWLINE\"\n",
    "syllable_dict[\",\"] = \"punc\"\n",
    "syllable_dict[\".\"] = \"punc\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tagging poems with the updated dictionary!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6596"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def syllables_poem(poem, untagged):\n",
    "    syllable_poem = []\n",
    "    for token in poem:\n",
    "        if(token in syllable_dict):\n",
    "            tag = syllable_dict[token]\n",
    "            syllable_poem = syllable_poem + [tag] \n",
    "        else:\n",
    "            untagged += [token]\n",
    "    return(syllable_poem, untagged)\n",
    "\n",
    "untagged = []\n",
    "syllable_poems = []\n",
    "for poem in poems.poems:\n",
    "    temp,untagged = syllables_poem(poem,untagged)\n",
    "    syllable_poems = syllable_poems+[temp]\n",
    "#set(b)\n",
    "len(set(untagged))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is still quite a few untagged words, despite all this. Although, upon inspection, the untagged words don't seem to contribute much, a lot also have unknown charachters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ERSONATION',\n",
       " 'SQUINTS',\n",
       " 'PILFERINGS',\n",
       " 'TRANSLATIONSARE',\n",
       " 'SPADING',\n",
       " 'VERMANDERO',\n",
       " \"'EAR\",\n",
       " 'DEI',\n",
       " 'MEANPRATE',\n",
       " 'MONSTRANCE',\n",
       " 'ARBORVITAE',\n",
       " 'WRACKT',\n",
       " 'BLAW',\n",
       " 'THYLACINE',\n",
       " 'MILKIE',\n",
       " 'HOMETHAT',\n",
       " 'BRUISÈD',\n",
       " 'HANDSDEMURELY',\n",
       " 'WADDLED',\n",
       " 'REMOVÈD',\n",
       " 'HUSBANDMANPAYS',\n",
       " 'TENNISING',\n",
       " 'PROCLAIME',\n",
       " 'LIBNI',\n",
       " 'EFFUSED',\n",
       " 'BURNTIN',\n",
       " 'BOLETUS',\n",
       " 'COMETO',\n",
       " 'BINGEING',\n",
       " 'JOSÉSAROUND',\n",
       " 'LIVINGUNDER',\n",
       " 'FLASKWITH',\n",
       " 'LEHUA',\n",
       " 'DENKEN',\n",
       " 'TWISTAS',\n",
       " 'CRAWLSHRILL',\n",
       " 'DOGALL',\n",
       " 'ALLUR',\n",
       " 'BLOSSOMTHE',\n",
       " 'REPASTS',\n",
       " 'INTEGRITIE',\n",
       " 'WHOMALL',\n",
       " 'TRANSIENCECRUSHED',\n",
       " 'REDACTI',\n",
       " 'INWITH',\n",
       " 'BOTTLEFUL',\n",
       " 'RAISEDIN',\n",
       " 'DEVICTUS',\n",
       " 'APPEAREDEVERY',\n",
       " 'ORGUNJÈ',\n",
       " 'LARKSONG',\n",
       " 'PORLOCK',\n",
       " 'MOTHEATEN',\n",
       " 'FUNFAIR',\n",
       " 'GEOGRAPHYNOW',\n",
       " 'ACCUSATIONALWAYS',\n",
       " 'OWNSKEWED',\n",
       " 'SWANNING',\n",
       " 'MAGNIFICAT',\n",
       " 'PRINCESSY',\n",
       " \"PRIS'NER\",\n",
       " 'PUREED',\n",
       " 'HERMANA',\n",
       " 'GAININGWEIGHT',\n",
       " 'UNPROCLAM',\n",
       " 'CORTÈGE',\n",
       " 'SOMEONE•',\n",
       " 'FISHNETS',\n",
       " 'BOUGHED',\n",
       " 'LUCASIA',\n",
       " 'CONSTITUTIVE',\n",
       " 'WRECCHED',\n",
       " 'PLOUGHSOCKS',\n",
       " 'SPIDERLIGHT',\n",
       " 'DEMANDINGTO',\n",
       " 'THROWNSTRAIGHT',\n",
       " 'VEO',\n",
       " 'RAINSPLIT',\n",
       " 'SLUSHED',\n",
       " 'GULPABLE',\n",
       " 'BACILLI',\n",
       " 'THATDARK',\n",
       " 'ACTIVENESS',\n",
       " 'TÖNNING',\n",
       " 'HAZELNUTCONFECTION',\n",
       " 'AUTHORITIE',\n",
       " 'FLODE',\n",
       " 'GREENSTUPID',\n",
       " 'HANDSAFTER',\n",
       " 'KENTISH',\n",
       " 'MARQUISE',\n",
       " 'DAYESYE',\n",
       " 'ROUNDHEADS',\n",
       " 'NOOKUNVISITED',\n",
       " 'HEARTHBEDS',\n",
       " 'DAUGHTERHOOD',\n",
       " 'PIERIAN',\n",
       " 'SUBJUGATING',\n",
       " 'POLVO',\n",
       " 'AGAINTHAT',\n",
       " 'UNFORTIFIED',\n",
       " 'LAURIER',\n",
       " 'TINTORETTO',\n",
       " 'ACTIUYTIE',\n",
       " 'ACTAEON',\n",
       " 'CONCEPTIONNODDED',\n",
       " 'ZOT',\n",
       " 'STEPOF',\n",
       " 'MATEAND',\n",
       " 'MILPA',\n",
       " 'HEVENLY',\n",
       " 'SEPULCHRAL',\n",
       " 'WHITSUNTIDE',\n",
       " 'PALLBEARERS',\n",
       " 'FRAYLE',\n",
       " 'UNBUILDING',\n",
       " 'ARMORS',\n",
       " 'FLINGER',\n",
       " '139',\n",
       " 'PERRUQUE',\n",
       " 'FENC',\n",
       " 'PARERS',\n",
       " 'WHOLOOKED',\n",
       " 'PHUC',\n",
       " 'HEIMAT',\n",
       " 'ONCET',\n",
       " \"BLUST'RING\",\n",
       " 'REPULST',\n",
       " 'METAMORPHOSED',\n",
       " 'WORDVOLKSWAGEN',\n",
       " 'POET\\ufeff',\n",
       " 'SEEBEYOND',\n",
       " 'TROLLEYBUS',\n",
       " 'AMANT',\n",
       " 'VORTEXTIQUE',\n",
       " 'BISCOCHITOS',\n",
       " '80S',\n",
       " 'HOUSELS',\n",
       " 'BIGWHEELS',\n",
       " 'HAWTREE',\n",
       " 'CIBOLA',\n",
       " 'UNREELS',\n",
       " 'NESTAND',\n",
       " 'STRAINERS',\n",
       " 'RIS',\n",
       " '\\ufeff\\ufeff\\ufeffVE',\n",
       " 'LIQUEFIESAS',\n",
       " 'LOOMDOOM',\n",
       " 'PORTHOLES',\n",
       " 'DUMDUM',\n",
       " 'ASKAR',\n",
       " 'THEHEAD',\n",
       " 'THIS…',\n",
       " 'CASQUE',\n",
       " 'CLINKINGWITH',\n",
       " 'CUZ',\n",
       " 'READ/RE',\n",
       " 'AMPHORÆ',\n",
       " 'SPLENETIC',\n",
       " 'SELTZERY',\n",
       " 'DEWLY',\n",
       " \"TEMP'RAMENT\",\n",
       " 'FEALTIE',\n",
       " 'FOSTERAGE',\n",
       " 'CURETTE',\n",
       " 'RUBIED',\n",
       " 'BACKLOVE',\n",
       " 'TRAINWITH',\n",
       " 'TMOLUS',\n",
       " 'WASPUSHING',\n",
       " 'PINKING',\n",
       " 'STOUTHEARTED',\n",
       " \"WORK'D\",\n",
       " 'GUESSIN',\n",
       " 'ALDERBEST',\n",
       " 'ENZYMIC',\n",
       " 'COMMODIFIED',\n",
       " 'SMARTAND',\n",
       " 'SEEMLY',\n",
       " 'DISCERNE',\n",
       " 'RADIONUCLIDES',\n",
       " 'GOLDORANGEN',\n",
       " 'ASSENTS',\n",
       " 'WATCHINGTHE',\n",
       " 'TAISHAN',\n",
       " 'SYNNE',\n",
       " 'LUDGATE',\n",
       " 'DANDLING',\n",
       " 'KHAKHAR',\n",
       " \"FLATT'RER\",\n",
       " 'INTHEIR',\n",
       " 'CURTAINAND',\n",
       " 'WANKERS',\n",
       " 'ADUMBRATIONS',\n",
       " 'BYZANTINES',\n",
       " 'ITURN',\n",
       " 'OVERDIGHT',\n",
       " 'LATERAND',\n",
       " 'REALER',\n",
       " 'LANGUE',\n",
       " 'OCTOROONS',\n",
       " 'PLATRES',\n",
       " 'ASPERGED',\n",
       " 'LEAVESOF',\n",
       " 'POSEUR',\n",
       " 'FULFILS',\n",
       " 'AOIBHINN',\n",
       " 'CHEVYUS',\n",
       " 'MEMMIUS',\n",
       " 'PARALYTICSAT',\n",
       " 'PASSEDAS',\n",
       " \"'SO\",\n",
       " 'BRACHES',\n",
       " 'FINACÉE',\n",
       " 'QUALMES',\n",
       " 'SQUAB',\n",
       " '750,000',\n",
       " 'BEDSHEET',\n",
       " 'PROSTRATIONS',\n",
       " 'QUANDARINESS',\n",
       " 'RETURNSA',\n",
       " 'NATURALL',\n",
       " 'FÓS',\n",
       " 'PARKEDHIS',\n",
       " 'DISORDERD',\n",
       " 'COURTYER',\n",
       " 'LŪ',\n",
       " 'NOCHT',\n",
       " 'UNSHELTERED',\n",
       " 'STRYVE',\n",
       " 'TOWARDA',\n",
       " 'PVC',\n",
       " \"DISBURD'ND\",\n",
       " 'ATOLLS',\n",
       " 'DRUMSTICKS',\n",
       " 'SAYNE',\n",
       " 'LOOKAT',\n",
       " 'THOMBE',\n",
       " 'FOOTPRINTSON',\n",
       " 'SKYVIEW',\n",
       " 'SCOSSE',\n",
       " 'NEVERHAD',\n",
       " 'RÎNJEŞTE',\n",
       " 'PREPS',\n",
       " 'SKIDMARK',\n",
       " 'LUNGWORT',\n",
       " 'UNDISPOSED',\n",
       " 'PEEPHOLES',\n",
       " 'EMBATTELD',\n",
       " 'ABYDOS',\n",
       " 'APPEARD',\n",
       " 'INACCESSIBILITYI',\n",
       " 'BESHAKEN',\n",
       " 'BOOTBLACKENINGAT',\n",
       " 'BACKWARDTOWARD',\n",
       " 'AMIEL',\n",
       " 'ANAGOGIC',\n",
       " 'SENSESMAKE',\n",
       " 'GRAVED',\n",
       " 'EFFICACYOF',\n",
       " 'KINGHOOD',\n",
       " 'TROPISMS',\n",
       " 'FRITILLARIES',\n",
       " 'ADRIAEN',\n",
       " 'GLEETHE',\n",
       " 'MOONWALK',\n",
       " 'LAPACCIA',\n",
       " 'BETTRE',\n",
       " 'DIVIL',\n",
       " 'WOMANISH',\n",
       " 'EXEGETES',\n",
       " 'KERCHIEFED',\n",
       " 'ROO',\n",
       " 'VEGASAND',\n",
       " 'ROOTWORKS',\n",
       " 'SPECTIVE',\n",
       " 'HUMMETH',\n",
       " 'SLEEPWITH',\n",
       " 'BEFORETHEY',\n",
       " 'APORIA',\n",
       " 'LIVELONG',\n",
       " 'HUNKA',\n",
       " 'CIÚNAS',\n",
       " '≈',\n",
       " 'NÁÁHASDŁÍÍ',\n",
       " '\\ufeff\\ufeff\\ufeffCLOCK',\n",
       " 'DESVELO',\n",
       " 'NONEAND',\n",
       " 'BRISS',\n",
       " 'YOURFACE',\n",
       " 'SSILHOUETTE',\n",
       " 'NOOTROPICS',\n",
       " 'OCCITAN',\n",
       " 'PLESAUNT',\n",
       " 'UNHYGIENIC',\n",
       " 'LINEANYTHING',\n",
       " 'WATERSPOUT',\n",
       " 'BEYONDTHIS',\n",
       " 'TAPESTRIED',\n",
       " '\\ufeff\\ufeff\\ufeffADDITION',\n",
       " 'RUINA',\n",
       " 'BETTEROFF',\n",
       " 'MAXILLARIES',\n",
       " 'SEASONOF',\n",
       " 'LOTHELY',\n",
       " 'WILLINGBORO',\n",
       " 'SHABBIEST',\n",
       " 'BOLTERED',\n",
       " 'LUBRICATES',\n",
       " 'HŮRA',\n",
       " 'DOWERED',\n",
       " 'EYELIGHT',\n",
       " 'POORGUSHES',\n",
       " 'CXLVIII',\n",
       " 'LIFETIMEWE',\n",
       " 'FLOURETTES',\n",
       " 'GOSPELLING',\n",
       " 'KATZEV',\n",
       " 'OAKENED',\n",
       " 'SCHIAPARELLI',\n",
       " 'BAITH',\n",
       " 'LINEDCOAT',\n",
       " 'SALVING',\n",
       " 'REVERIESOF',\n",
       " 'STOPPEDCLAMORING',\n",
       " 'HAPPENTER',\n",
       " 'UPTHOSE',\n",
       " 'IHAB',\n",
       " 'GENERAL=FOR',\n",
       " 'STRABISMUS',\n",
       " 'TEMPORALITY',\n",
       " 'DOUBTOR',\n",
       " 'MOLLIOR',\n",
       " 'MWOLDRÈN',\n",
       " 'GROUNDYOU',\n",
       " 'LANDWHERE',\n",
       " 'PASSED/',\n",
       " 'PILWE',\n",
       " 'SHAPLESSNESS',\n",
       " 'CONCEALD',\n",
       " 'HONEYBUNCH',\n",
       " '艾未未',\n",
       " 'CHEART',\n",
       " 'PRAISEEVEN',\n",
       " 'FCC',\n",
       " 'UPAGAINST',\n",
       " 'REFLEXSIMPLE',\n",
       " 'DREAMSYOU',\n",
       " 'OFGEĀFON',\n",
       " 'IKKYŪ',\n",
       " 'BASHŌ',\n",
       " 'WAXWINGS',\n",
       " 'OBDUR',\n",
       " 'NECTARY',\n",
       " 'ERNŐWAS',\n",
       " 'BOLCHEVIKI',\n",
       " 'LIVIN',\n",
       " 'EARTHCOOLNESS',\n",
       " 'PROBLEMSOF',\n",
       " 'SCIENTIAL',\n",
       " 'BIOTERROR',\n",
       " 'ALLYOUR',\n",
       " '\\ufeffHEAVED',\n",
       " 'BAGSINSIDE',\n",
       " 'CUNIGUNDE',\n",
       " 'ETTRICK',\n",
       " 'AGGRIEVEMENT',\n",
       " 'BANDSOF',\n",
       " 'DUTCHES',\n",
       " 'É\\ufeffPIPHANIE',\n",
       " 'TECHOS',\n",
       " 'YALLAH',\n",
       " 'BLESSSOMETHING',\n",
       " 'WYTCHES',\n",
       " 'NUMINOUS',\n",
       " 'AMARE',\n",
       " 'SCEPTRAL',\n",
       " 'RADEAUX',\n",
       " 'WINDOWLIGHT',\n",
       " 'CLEPES',\n",
       " 'BEAUTÉ',\n",
       " 'SUPERFLY',\n",
       " 'OUTSPEAKS',\n",
       " 'HITHE',\n",
       " 'IMPORTUNATE',\n",
       " 'PARAPETS',\n",
       " 'EINSTEINONCE',\n",
       " 'EOHO',\n",
       " 'RIN',\n",
       " 'ENDOWD',\n",
       " 'ENJOYND',\n",
       " 'HUSTLIN',\n",
       " 'BLINGS',\n",
       " 'TACHYCARDIA',\n",
       " 'SAIDONCE',\n",
       " 'SNOWMELTING',\n",
       " 'GLADDER',\n",
       " 'VOLA',\n",
       " 'PREFABRICATIONS',\n",
       " 'CHẾT',\n",
       " 'GRIESLY',\n",
       " 'SLIMING',\n",
       " 'HUSWIFE',\n",
       " \"EV'NING\",\n",
       " 'FAREWEL',\n",
       " 'INTERROGATIVE',\n",
       " 'DISENCUMBERED',\n",
       " 'COPULATED',\n",
       " 'FORDED',\n",
       " 'STOODPOINTING',\n",
       " 'THINKSOMETHING',\n",
       " 'JOINEDGREAT',\n",
       " 'UNDISGUIS',\n",
       " 'UNDULANT',\n",
       " \"NUM'ROUS\",\n",
       " 'KICKT',\n",
       " 'ANALEMMAS',\n",
       " 'SHIRTTAILS',\n",
       " 'CLIME',\n",
       " 'TACHISTS',\n",
       " 'NIGHTSWEAT',\n",
       " '\\u200bAFTER',\n",
       " 'ONLYPAST',\n",
       " 'JOSÉ',\n",
       " 'DREADLOCK',\n",
       " 'TIMESAYS',\n",
       " 'ANOTHERPLACE',\n",
       " 'SWALLOWD',\n",
       " 'KILCLOHER',\n",
       " 'BELMONDO',\n",
       " 'MEANNO',\n",
       " 'BACKAND',\n",
       " 'PLEASEST',\n",
       " 'BLISSES',\n",
       " 'CATTIVI',\n",
       " 'EYEFIRST',\n",
       " 'BLINIS',\n",
       " 'CRISPISSA',\n",
       " 'CHERSONESS',\n",
       " '369TH',\n",
       " 'HENOREOS',\n",
       " 'BEREVIT',\n",
       " 'WOONE',\n",
       " 'FOURSCORE',\n",
       " 'PÉLEUS',\n",
       " 'POTOF',\n",
       " 'UNVEERING',\n",
       " 'ANDNEARER',\n",
       " '\\ufeffBUT',\n",
       " 'WORDEVERYTHING',\n",
       " 'FUNNYBUT',\n",
       " 'SERPENTE',\n",
       " 'BILEAND',\n",
       " 'GROUNDWHERE',\n",
       " '美',\n",
       " 'BULGINGWITH',\n",
       " 'PARTURITION',\n",
       " 'WUNKS',\n",
       " 'LOVEANDANTE',\n",
       " 'SWĀGH',\n",
       " 'ARMORTO',\n",
       " 'NIÉPCERECORDED',\n",
       " 'HOLODECKS',\n",
       " 'STILLLIVING',\n",
       " 'HWŒ\\ufeffR',\n",
       " 'AWAKEMY',\n",
       " 'NUESTROS',\n",
       " 'NIGHTMARESSHARP',\n",
       " 'BARNACLED',\n",
       " 'NOWTHE',\n",
       " 'EYESOF',\n",
       " 'REMITTING',\n",
       " 'FINALLYSEEMS',\n",
       " 'ALABASTEREYELIDS',\n",
       " 'EUCHARISTS',\n",
       " 'VERMIVOROUS',\n",
       " 'GOATSAND',\n",
       " 'PLAYEDHIS',\n",
       " 'BASICNESS',\n",
       " \"BESTOW'D\",\n",
       " 'ANDACROSS',\n",
       " 'EMBLAZONRY',\n",
       " 'PRIKYNG',\n",
       " 'SISTERGIRL',\n",
       " 'FOULMOUTHED',\n",
       " 'MURRES',\n",
       " 'BEVELED',\n",
       " 'DIGESTSTHE',\n",
       " '2:10',\n",
       " 'CONTORTIONISTS',\n",
       " 'HASALREADY',\n",
       " 'ORTS',\n",
       " 'OVERSPILLS',\n",
       " 'COWESLEPE',\n",
       " 'SORDELLUS',\n",
       " 'DISPERST',\n",
       " 'TRYELYCHE',\n",
       " 'LAUND',\n",
       " 'CONSCIOUSCARING',\n",
       " 'NASUTION',\n",
       " 'STAUNCHING',\n",
       " 'SHIRTAND',\n",
       " \"'GENERAL\",\n",
       " 'UNEXPRESS',\n",
       " 'PLEROMATIC',\n",
       " 'HAPHAZARDED',\n",
       " 'BIRDMUSIC',\n",
       " 'UNPUNISH',\n",
       " 'SQUINCHED',\n",
       " 'BREVITATE',\n",
       " 'TUGON',\n",
       " 'FISTWILL',\n",
       " 'EPITAPHIC',\n",
       " 'SPITTLEIN',\n",
       " 'DAMN/',\n",
       " 'STANNIN',\n",
       " 'LUS',\n",
       " 'ARALIAN',\n",
       " 'ALCÆUS',\n",
       " 'ARTWORKIN',\n",
       " 'YEMIT',\n",
       " 'HOLEY',\n",
       " 'PEOPLEHAVE',\n",
       " 'PRETORS',\n",
       " 'TIDIED',\n",
       " 'CORNCAKES',\n",
       " 'UNOBSERV',\n",
       " \"VOUTSAF'ST\",\n",
       " 'MYNES',\n",
       " 'SOTHFAST',\n",
       " 'PROBLEM–AND',\n",
       " 'NOWFOR',\n",
       " 'ÁFRICA',\n",
       " 'BRAIN/HANDS',\n",
       " 'FOOTSTOOL',\n",
       " 'PATHWAIE',\n",
       " 'LETZTEN',\n",
       " 'GARDENLATE',\n",
       " 'READINGTHE',\n",
       " 'TONIGHTTHE',\n",
       " 'CLANGS',\n",
       " 'MANDIR',\n",
       " 'ALMOSTUNDERSTAND',\n",
       " 'JEBUSITES',\n",
       " 'MILDEWY',\n",
       " 'WHATWON',\n",
       " 'REVEILLE',\n",
       " 'YEWEY',\n",
       " 'FLASHLIT',\n",
       " 'OFOLD',\n",
       " 'CRAME',\n",
       " 'THÍCH',\n",
       " 'PYRAMIDION',\n",
       " 'NURTUR',\n",
       " 'BRUSHEDA',\n",
       " 'MUSAGETES',\n",
       " 'SONGSABOUT',\n",
       " 'OOF',\n",
       " 'WHOLY',\n",
       " 'INSTRUMENTTHAT',\n",
       " 'DOIRE',\n",
       " 'ACROSSSOGGY',\n",
       " 'FLATTING',\n",
       " 'DOMELIKE',\n",
       " 'DANCELIKE',\n",
       " 'LEGSHIGH',\n",
       " 'PLANETREINCARNATEANYWHEREBUT',\n",
       " 'SLAPHIS',\n",
       " 'ICELACE',\n",
       " 'WATCHMAKERS',\n",
       " 'UNMERITED',\n",
       " 'TIPCOMES',\n",
       " 'SAIDLOW',\n",
       " 'SKYES',\n",
       " 'CLEER',\n",
       " 'WHITEWALL',\n",
       " 'GREASEWILL',\n",
       " 'NAMESIN',\n",
       " '★',\n",
       " 'VAMPYRE',\n",
       " 'KNIVE',\n",
       " 'EXPELD',\n",
       " 'CONCATENATIONS',\n",
       " 'SLIPTESTING',\n",
       " 'CHOAKED',\n",
       " 'BELOWTHE',\n",
       " 'PLANTOWARD',\n",
       " 'MOLOCH',\n",
       " 'SCRAWLINGS',\n",
       " 'WORKST',\n",
       " 'TOUCHSCREEN',\n",
       " 'DOGDOM',\n",
       " \"MI'KMAQ\",\n",
       " 'DVOŘÁK',\n",
       " 'WRISTUSELESSLY',\n",
       " 'MONEYLENDERS',\n",
       " 'ROWLAUGHED',\n",
       " 'IRREDEEMABLE',\n",
       " 'MOPEAND',\n",
       " 'MIEKAL',\n",
       " \"HIDD'ST\",\n",
       " 'ASGMT',\n",
       " 'GRACKLESCONGREGATED',\n",
       " 'GAUFRES',\n",
       " 'UNSCRATCHED',\n",
       " 'BICAUSE',\n",
       " 'TOXODON',\n",
       " 'FATHE',\n",
       " 'ALBORAN',\n",
       " 'WHILSE',\n",
       " 'BIGISHKADA',\n",
       " 'NA',\n",
       " 'AUSONIAN',\n",
       " 'HEDGEROWSSHAKESPEARE',\n",
       " 'BHAGAVAD',\n",
       " 'DUNHUANG',\n",
       " 'IMPORTUNE',\n",
       " 'CEPHALONIA',\n",
       " 'TRICKLINGTHROUGH',\n",
       " 'HURTLED',\n",
       " 'VOLIED',\n",
       " 'REAPD',\n",
       " 'SOPPRESSATA',\n",
       " 'MAKAH',\n",
       " 'TROWELING',\n",
       " 'NIMBOSTRATUS',\n",
       " 'ELYSÉES',\n",
       " 'ARMATA',\n",
       " 'CANSLISTENYOU',\n",
       " 'MADETHE',\n",
       " 'SHECRASHED',\n",
       " 'STINKBALL',\n",
       " 'GOODGIRAFFES',\n",
       " 'WHIRLIGIGS',\n",
       " 'PACEFROM',\n",
       " 'SINGEN',\n",
       " 'DIONYS̄US',\n",
       " 'STREETCHATTING',\n",
       " 'YONGER',\n",
       " 'IVAIN',\n",
       " 'ANTHROPOMORPHIA',\n",
       " 'ERLONE',\n",
       " 'MONTEROSA',\n",
       " 'LÉI',\n",
       " 'STOOPT',\n",
       " 'FIELDSVIBRANT',\n",
       " 'LARFED',\n",
       " \"FARQU'AR\",\n",
       " 'BONDONE',\n",
       " 'BRETHERHED',\n",
       " 'NOWHERETO',\n",
       " 'BEMUS',\n",
       " 'SIDEWINDING',\n",
       " 'SALTE',\n",
       " 'GILLYFISH',\n",
       " 'BOTTLEWITH',\n",
       " 'FORWARDNESS',\n",
       " 'DEFLOURD',\n",
       " 'THARRAY',\n",
       " 'MINDES',\n",
       " 'CH2O',\n",
       " 'WHEREFORTH',\n",
       " 'MUFFED',\n",
       " 'ENLIL',\n",
       " 'FITTINGARTEMISIA',\n",
       " 'SOFALA',\n",
       " 'SHADOW⎯BUT',\n",
       " 'FLESHTRANSPARENT',\n",
       " 'BLUBBERING',\n",
       " \"'EM\",\n",
       " 'DRYBONE',\n",
       " 'HAZILY',\n",
       " 'THEYRE',\n",
       " 'IRASCIBILITY',\n",
       " 'DIOTIMA',\n",
       " 'WESER',\n",
       " 'DOGGER',\n",
       " 'CORKSCREWS',\n",
       " '你',\n",
       " 'CHRISTS',\n",
       " 'TRUEAND',\n",
       " 'SOTH',\n",
       " 'FINGERSAND',\n",
       " 'BILGE',\n",
       " 'BASKETING',\n",
       " 'HEARWHAT',\n",
       " \"EEV'NING\",\n",
       " 'GOSTLY',\n",
       " 'YOREMEM',\n",
       " 'TELEVISIONSET',\n",
       " 'LOVEHE',\n",
       " 'LEARNABOUT',\n",
       " 'LÖFFEL',\n",
       " 'PINCER',\n",
       " 'DOLLARED',\n",
       " 'UPRAISEST',\n",
       " 'MARBLEIZED',\n",
       " 'PORTUÑOL',\n",
       " 'SHELLHEAP',\n",
       " 'BACKLITAND',\n",
       " \"'WAS\",\n",
       " 'REWARDE',\n",
       " 'BLINKER',\n",
       " 'TĪPUNA',\n",
       " '\\u200bSOMEWHERE',\n",
       " 'POINTLESSNESS',\n",
       " 'CHEANN',\n",
       " 'FULGENCE',\n",
       " 'HEADSCARVES',\n",
       " 'LUCYSONG',\n",
       " 'SCINTILLATE',\n",
       " 'MOTORSCOOTERS',\n",
       " 'FIBRILLATE',\n",
       " 'PRAISEIN',\n",
       " 'UNALARMING',\n",
       " 'ISNEVER',\n",
       " '•ONE',\n",
       " 'LASCIA',\n",
       " 'EVERLASTINGNESS',\n",
       " 'JAPING',\n",
       " 'SAVITH',\n",
       " 'FUTUREYOU',\n",
       " 'HUNGERAND',\n",
       " 'PHONELINES',\n",
       " 'RUMBA',\n",
       " 'HAMBONE',\n",
       " 'TULARE',\n",
       " 'VOICEWE',\n",
       " 'PRINGLED',\n",
       " 'AGHABOG',\n",
       " 'UNAWAKE',\n",
       " 'WISHFULL',\n",
       " 'AMPLEST',\n",
       " 'KWHENG',\n",
       " 'CHRISTENS',\n",
       " 'DAINTIES',\n",
       " 'BEATINGDOWN',\n",
       " 'AVAIT',\n",
       " 'GLADNESS',\n",
       " 'CLOUDCOCKED',\n",
       " 'ROWEL',\n",
       " 'CUPLESS',\n",
       " 'OUTWATCH',\n",
       " 'FEBRIS',\n",
       " '10:35',\n",
       " 'BOGALUSA',\n",
       " 'GONGSFOR',\n",
       " 'MISTED',\n",
       " 'TARPAULIN',\n",
       " 'SELECTORS',\n",
       " 'ESPERANDO',\n",
       " 'COUNTNANCE',\n",
       " 'HEORE',\n",
       " 'LEAVESOME',\n",
       " 'ENDHIYA',\n",
       " 'ARRAIGND',\n",
       " 'BRI',\n",
       " 'WHICHWE',\n",
       " 'SEAWARDS',\n",
       " 'CYCLOP',\n",
       " 'MOUTHIN',\n",
       " 'RONGE',\n",
       " 'FRÓM',\n",
       " 'INGRATITUDE',\n",
       " 'FISHMOUTHS',\n",
       " 'NOBODYRESPONDING',\n",
       " 'TWOBEARS',\n",
       " 'BRENNBAUM',\n",
       " 'ISRAFELI',\n",
       " 'LAST⎯THE',\n",
       " 'FACEAND',\n",
       " 'OPERATINGIN',\n",
       " 'KYNGES',\n",
       " 'DIMGUTTERING',\n",
       " 'FRANKENSTEINING',\n",
       " 'TROUBLESHOOT',\n",
       " 'BRINKSMEN',\n",
       " 'JEHOVA',\n",
       " \"DIDN'TTOUCH\",\n",
       " 'AFRASIAB',\n",
       " 'HOMEROOM',\n",
       " 'BOYWE',\n",
       " 'LEASTSOME',\n",
       " '_________________',\n",
       " 'SWEDENBORG',\n",
       " 'HIERARCH',\n",
       " 'MADDEST',\n",
       " 'BONNIEST',\n",
       " 'BOOTLESS',\n",
       " 'OVERBALANCING',\n",
       " 'LOWERTOWN',\n",
       " 'ORDURE',\n",
       " 'ĐÔNG',\n",
       " 'PHOTORECEPTORS',\n",
       " 'SURRROUNDING',\n",
       " 'KN',\n",
       " 'GRANDOH',\n",
       " 'AGGERVATES',\n",
       " 'DUCKUNDER',\n",
       " 'CONCUSSES',\n",
       " 'LATRINAL',\n",
       " 'BARER',\n",
       " 'UNLADED',\n",
       " 'SCROLLED',\n",
       " 'REJOYC',\n",
       " 'NUMBS',\n",
       " 'SEAV',\n",
       " 'UNCRUMPLE',\n",
       " 'DĘBORÓG',\n",
       " 'IMMENSITY',\n",
       " 'ERSHADOW',\n",
       " \"'LOOK\",\n",
       " 'FLAYERS',\n",
       " 'KŪPUNA',\n",
       " 'ANDCOME',\n",
       " 'TRIVETS',\n",
       " 'GALLANTER',\n",
       " 'CHEWD',\n",
       " 'DISSEMBLED',\n",
       " 'ONESVALLEY',\n",
       " 'NECKBANE',\n",
       " 'SYNCOPATES',\n",
       " 'FLAMBÉ',\n",
       " 'BRUSCHETTA',\n",
       " 'BACKDARK',\n",
       " 'ARECACEAE',\n",
       " 'MARTIR',\n",
       " 'LENTICULAR',\n",
       " 'APPROVETHOSE',\n",
       " 'ŌHI',\n",
       " 'QINGPING',\n",
       " 'BLAOSC',\n",
       " 'QUATERNAL',\n",
       " 'VARNISHINSTEAD',\n",
       " 'LOOKSTHAT',\n",
       " 'MINDLIKE',\n",
       " 'EGRETS',\n",
       " 'ACTTHE',\n",
       " 'NOBBUT',\n",
       " 'EGLINTOUN',\n",
       " 'STRAWSON',\n",
       " 'GROWSWITHIN',\n",
       " 'SEETO',\n",
       " 'TRANSFORMEDWALK',\n",
       " 'SCATTERS',\n",
       " 'LIZARDSKIN',\n",
       " 'SEEKINGS',\n",
       " 'ROOFY',\n",
       " 'TOTHE',\n",
       " 'AGEN',\n",
       " 'SNOW…',\n",
       " 'COLLEGELANDS',\n",
       " 'ITALICIZE',\n",
       " 'PATINAS',\n",
       " 'ALFRESCO',\n",
       " 'WYCLIFFE',\n",
       " 'MNE',\n",
       " 'BOOK…',\n",
       " 'FABULA',\n",
       " 'NOSOTROS',\n",
       " '•ON',\n",
       " 'DUNCES',\n",
       " 'WASFELT',\n",
       " 'AFTERDRAFT',\n",
       " 'LEFTBUT',\n",
       " 'HIDDOUS',\n",
       " 'AIR/',\n",
       " 'UNSOUGHT',\n",
       " 'IMAG',\n",
       " '*YOU',\n",
       " 'DEJECTION',\n",
       " 'ΚΟΡΑΙ',\n",
       " 'FUTURELESS',\n",
       " 'EIDOLON',\n",
       " 'TOLLEN',\n",
       " 'BOWELLS',\n",
       " 'MILITARISME',\n",
       " 'THOUGHTO',\n",
       " 'VIOLENTSTATE',\n",
       " 'FAINTAND',\n",
       " 'FUNERALWITHOUT',\n",
       " '1930S',\n",
       " 'CONVULS',\n",
       " 'SLES',\n",
       " 'ABOMINABLY',\n",
       " 'TROUVONS',\n",
       " 'TWE',\n",
       " 'VAY',\n",
       " 'UNCROSSING',\n",
       " 'ARCHIVED',\n",
       " 'VERANDAHS',\n",
       " 'BATHTIME',\n",
       " 'ALLTO',\n",
       " 'PIANTO',\n",
       " 'EINEN',\n",
       " 'KITTIWAKES',\n",
       " 'BLOWINGCHASES',\n",
       " '64WHEN',\n",
       " \"HEAR'ST\",\n",
       " 'BLACKLEGGED',\n",
       " 'TSAT',\n",
       " 'DESTROYEDBY',\n",
       " 'SHŌNAGON',\n",
       " 'ŻEGARYNO',\n",
       " 'COLORATIONS',\n",
       " 'UNMISERABLE',\n",
       " 'SOLDIERSWERE',\n",
       " 'PINIONS',\n",
       " 'GAROFANI',\n",
       " 'UPROSE',\n",
       " 'CLOSETO',\n",
       " 'DESCENDETH',\n",
       " 'MYNAHS',\n",
       " 'ĐIÊN',\n",
       " 'TINTING',\n",
       " 'CONSC',\n",
       " 'RISESO',\n",
       " 'TINNULA',\n",
       " 'EYEDSPIDERS',\n",
       " 'WHOS',\n",
       " 'SAIDAND',\n",
       " 'FORYEFNESS',\n",
       " 'VIDEANT',\n",
       " 'MERCÚRYE',\n",
       " 'STONEAS',\n",
       " \"O'ERGIVEN\",\n",
       " 'CORDWOOD',\n",
       " 'DISINTHRONE',\n",
       " 'UNBUCKLED',\n",
       " 'DEIFIE',\n",
       " 'UNDECODED',\n",
       " 'PERSONIN',\n",
       " 'INDUSTRIOUSAS',\n",
       " 'TUKUP',\n",
       " 'TURNEDST',\n",
       " 'TRIUMPHINGS',\n",
       " 'TWERPY',\n",
       " 'THEMSELUES',\n",
       " 'ORIONDREW',\n",
       " 'BROUGHTAGAINST',\n",
       " 'OON',\n",
       " 'ANALYS',\n",
       " 'REQUIRES…',\n",
       " 'DESTRUCTORS',\n",
       " 'HEDAMN',\n",
       " 'QUIRT',\n",
       " 'COLORINGS',\n",
       " 'GENTLEEN',\n",
       " 'GOTILL',\n",
       " 'NOOR',\n",
       " 'STUBBLED',\n",
       " 'FORMLESS',\n",
       " 'STREWNTHE',\n",
       " 'CUTIRIS',\n",
       " 'UNDISEASED',\n",
       " 'TAGALOAALAGI',\n",
       " 'COVERLET',\n",
       " 'WAYLAYS',\n",
       " 'TIGHTOVER',\n",
       " 'BLOODSTRUCK',\n",
       " 'WALKEST',\n",
       " 'MARYSYA',\n",
       " 'CLAVERS',\n",
       " 'INTESTIN',\n",
       " 'TOESOPEN',\n",
       " 'STIRR',\n",
       " 'IIMAGINE',\n",
       " '43',\n",
       " 'EFFLUENTS',\n",
       " 'MANWHO',\n",
       " 'AK',\n",
       " 'SHITSLINGER',\n",
       " 'BEAUROCRAT',\n",
       " 'RETEACH',\n",
       " 'IVBEAT',\n",
       " 'AWAYIS',\n",
       " 'MARUNGA',\n",
       " 'SAVIORS…',\n",
       " 'KĀNAKA',\n",
       " 'FRESHNESSTO',\n",
       " 'CANNOTTOUCH',\n",
       " 'PAPILLAE',\n",
       " 'BELOVÉD',\n",
       " 'PISTOIA',\n",
       " '1988',\n",
       " 'MICHAEL…',\n",
       " 'HERBIVORES',\n",
       " 'INSUBSTANTIALITY',\n",
       " 'GIRLSWITH',\n",
       " 'POLONAISES',\n",
       " 'WORKSHIRT',\n",
       " 'CONFEDERATES',\n",
       " 'WHOWHAT',\n",
       " 'SHIRRING',\n",
       " 'SUCCORS',\n",
       " 'POEMTHAT',\n",
       " 'RETICULUM',\n",
       " 'ARTILLERIES',\n",
       " 'WASHEDTHEIR',\n",
       " 'SIQUIJOR',\n",
       " ...}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(untagged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the N-gram and HMM model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the logic and code for nGrams was explained in the N-Gram-Basic notebook. Now the code is modularized. Read the documentation for details on building the n-Grams model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "TriGram = model.nGrams(poems.poems,3)\n",
    "FourGram = model.nGrams(poems.poems,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TriGram.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_word1 = 2\n",
    "prev_word2 = 2\n",
    "prev_word3 = 2\n",
    "prev_word4 = 2\n",
    "prev_word5 = 3\n",
    "prev_word6 = 2\n",
    "prev_word7 = 3\n",
    "\n",
    "generate_str = str(prev_word1)+\" \"+str(prev_word2) + \" \" +str(prev_word3) + \" \"+ str(prev_word4) +\" \"+str(prev_word5) + \" \" +str(prev_word6) + \" \" +str(prev_word7)\n",
    "\n",
    "for i in range(50):\n",
    "    next_word  = n.next_word([prev_word1, prev_word2,prev_word3,prev_word4, prev_word5,prev_word6,prev_word7], dic8, 8)\n",
    "    prev_word1 = prev_word2\n",
    "    prev_word2 = prev_word3\n",
    "    prev_word3 = prev_word4\n",
    "    prev_word4 = prev_word5\n",
    "    prev_word5 = prev_word6\n",
    "    prev_word6 = prev_word7\n",
    "    prev_word7 = next_word\n",
    "    generate_str = generate_str+\" \"+ str(next_word)\n",
    "\n",
    "print(generate_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic8 = {}\n",
    "for i in syllable_poems:\n",
    "    dic8 = a.NGram(dic8, i, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_word([11], dicBi, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_word_prob(words, dic, nGram):\n",
    "    Max = -inf\n",
    "    next_word = \"\"\n",
    "    dictionary = dic\n",
    "    for word in words:\n",
    "        dictionary = dictionary[word]\n",
    "    \n",
    "    if(not(list(dictionary.values())[0]<1)):\n",
    "        total_counts = 0\n",
    "        for i,j in list(dictionary.items()):\n",
    "            total_counts = total_counts+j\n",
    "        print(total_counts)\n",
    "        items = list(dictionary.items())\n",
    "        alpha = 0.1*total_counts\n",
    "        for i,j in items:\n",
    "            dictionary[i] = ((j+alpha)/(total_counts + alpha*len(items)))\n",
    "\n",
    "    for i,j in list(dictionary.items()):\n",
    "        if(j>Max):\n",
    "            Max = j\n",
    "            next_word = i\n",
    "    return(next_word, Max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicBi = {}\n",
    "for i in syllable_poems:\n",
    "    dicBi = n.BiGram(dicBi, i)\n",
    "for j in range(13):\n",
    "    print(j, next_word([j], dicBi, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicBi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dicTri = {}\n",
    "#for i in syllable_poems:\n",
    "#    dicTri = n.TriGram(dicTri, i)\n",
    "    \n",
    "next_word([\"NEWLINE\",4], dicTri,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicTri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_database[dict_database.syllable_count ==13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictSyllable = {}\n",
    "for i in dict_database.syllable_count.unique():\n",
    "    dictSyllable[i] = list((dict_database[dict_database.syllable_count ==i]).words)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
