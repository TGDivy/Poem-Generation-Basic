{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Data\n",
    "import Models\n",
    "from Models import nGrams as n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "poems = Data.PoetryFoundationPoems()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "poems = Data.Poem_words_dict(poems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "poem_syllables = Data.PoemOfSyllables(poems)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ngram model for both Syllables and Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Models.nGrams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "WordsTri = {}\n",
    "for i in poems:\n",
    "    WordsTri = a.NGram(WordsTri, i,3)\n",
    "\n",
    "Words4 = {}\n",
    "for i in poems:\n",
    "    Words4 = a.NGram(Words4, i, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Syllables3 = {}\n",
    "for i in poem_syllables:\n",
    "    Syllables3 = a.NGram(Syllables3, i, 3)\n",
    "\n",
    "Syllables4 = {}\n",
    "for i in poem_syllables:\n",
    "    Syllables4 = a.NGram(Syllables4, i, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_by_syllables = Data.words_by_syllables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('RIVERBANK', 0.25)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.next_word_prob([\"ALONG\",\"THAT\"], WordsTri, 3, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'RIVERBANK': 0.25,\n",
       " 'RIVER': 0.125,\n",
       " 'LINE': 0.125,\n",
       " 'GROVE': 0.125,\n",
       " 'PATHLESS': 0.125,\n",
       " 'TABLE': 0.125,\n",
       " 'PLANE': 0.125}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WordsTri[\"ALONG\"][\"THAT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 0.563461527846012)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.next_word_prob([2,1], Syllables3, 3, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'punc': 0.12508487113387834,\n",
       " 'NEWLINE': 0.052117776293491284,\n",
       " 2: 0.1703439557952494,\n",
       " 1: 0.563461527846012,\n",
       " 3: 0.044356552603542786,\n",
       " 4: 0.011230590040682943,\n",
       " 0: 0.030545328085583225,\n",
       " 6: 0.0004084854573657104,\n",
       " 5: 0.002332231158608279,\n",
       " 8: 3.312044248911166e-05,\n",
       " 7: 6.624088497822332e-05,\n",
       " 15: 2.760036874092638e-06,\n",
       " 16: 2.760036874092638e-06,\n",
       " 9: 8.280110622277914e-06,\n",
       " 13: 2.760036874092638e-06,\n",
       " 14: 2.760036874092638e-06}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Syllables3[2][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Models import nGrams as nn\n",
    "def nextSyllabeWord(words, words_nGram, syllable_nGram, syllable_dic, n):\n",
    "    syllables = [syllable_dic[word] for word in words]\n",
    "    \n",
    "    wordsDic = words_nGram\n",
    "    syllaDic = syllable_nGram\n",
    "    \n",
    "    nn.next_word_prob(words, wordsDic, n, 0)\n",
    "    nn.next_word_prob(syllables, syllaDic, 0.5)\n",
    "    \n",
    "    for word in words:\n",
    "        wordsDic = wordsDic[word]\n",
    "    for syllable in syllables:\n",
    "        syllaDic = syllaDic[syllable]\n",
    "    \n",
    "    Max = 0\n",
    "    next_word = \"Error\"\n",
    "    #print(words)\n",
    "    \n",
    "    \n",
    "    for word,probablity_word in list(wordsDic.items()):\n",
    "        \n",
    "        final_prob = 0\n",
    "        if(word in syllable_dic):\n",
    "            word_syllable_count = syllable_dic[word] \n",
    "            final_prob = probablity_word * syllaDic[word_syllable_count]\n",
    "            \n",
    "        #print(word,probablity_word,syllaDic[word_syllable_count], final_prob)\n",
    "        if(final_prob>Max):\n",
    "            Max = final_prob\n",
    "            next_word = word\n",
    "    return(next_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LINE'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nextSyllabeWord([\"ALONG\",\"THAT\"], WordsTri, Syllables3,Data.SyllablesDict(),3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'WHY DREAM'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prev_word1 = \"WHY\"#words_by_syllables[2][random.randint(0,len(words_by_syllables[3]))]\n",
    "temp = list(WordsTri[prev_word1].keys())\n",
    "prev_word2 = \"DREAM\"#temp[random.randint(0,len(temp)-1)]\n",
    "generate_str = prev_word1+\" \"+prev_word2\n",
    "generate_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50):\n",
    "    next_word = nextSyllabeWord([prev_word1, prev_word2],  WordsTri, Syllables3,Data.SyllablesDict(),3)\n",
    "    prev_word1 = prev_word2\n",
    "    prev_word2 = next_word\n",
    "    generate_str = generate_str+\" \"+ next_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WHY DREAM I HAD A DREAM OF THE WORLD IS A KIND OF A MAN WHO HAS NOT BEEN TO ME , \n",
      "AND THE WORLD IS A KIND OF A MAN WHO HAS NOT BEEN TO ME , \n",
      "AND THE WORLD IS A KIND OF A MAN WHO HAS NOT\n"
     ]
    }
   ],
   "source": [
    "print(generate_str.replace(\"NEWLINE \",\"\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I DO NOT KNOW WHAT I MEAN IS NOT A LIE IF THE TELLER \n",
      "BELIEVES IT NEXT TIME THE MAN \n",
      "WHO COULD HAVE BEEN A YOUNG MAN WITH A NEW HAT \n",
      "IS RUNNING A STRIP OF THE EL LIKE A FRAME AMONG \n",
      "MEDLARS & . HAND ME THAT THERE\n"
     ]
    }
   ],
   "source": [
    "prev_word1 = \"I\"#words_by_syllables[2][random.randint(0,len(words_by_syllables[3]))]\n",
    "temp       = list(Words4[prev_word1].keys())\n",
    "prev_word2 = \"DO\"#temp[random.randint(0,len(temp)-1)]\n",
    "temp2      = list(Words4[prev_word1][prev_word2].keys())\n",
    "prev_word3 = \"NOT\"#temp2[random.randint(0,len(temp2)-1)]\n",
    "\n",
    "generate_str = prev_word1+\" \"+prev_word2 + \" \" +prev_word3\n",
    "#generate_str\n",
    "for i in range(50):\n",
    "    #print(generate_str)\n",
    "    next_words = nextSyllabeWord([prev_word1, prev_word2, prev_word3],  Words4, Syllables4,Data.SyllablesDict(),4)\n",
    "    prev_word1 = prev_word2\n",
    "    prev_word2 = prev_word3\n",
    "    prev_word3 = next_words\n",
    "    generate_str = generate_str+\" \"+ next_words\n",
    "print(generate_str.replace(\"NEWLINE \",\"\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I DO NOT KNOW \n",
      "HOW TO MAKE THE WORLD SAFE FOR DEMOCRACY , \n",
      "YOU ’ RE A LITTLE BIT \n",
      "ABOUT THE FLOWERS IN THE STALLS , AND THE LONG , LONG THOUGHTS . `` I REMEMBER THE FIRST TIME , \n",
      "AND THE WORLD IS A ROAD UNDER THE WALL\n"
     ]
    }
   ],
   "source": [
    "prev_word1 = \"I\"#words_by_syllables[2][random.randint(0,len(words_by_syllables[3]))]\n",
    "temp       = list(Words4[prev_word1].keys())\n",
    "prev_word2 = \"DO\"#temp[random.randint(0,len(temp)-1)]\n",
    "temp2      = list(Words4[prev_word1][prev_word2].keys())\n",
    "prev_word3 = \"NOT\"#temp2[random.randint(0,len(temp2)-1)]\n",
    "generate_str = prev_word1+\" \"+prev_word2 + \" \" +prev_word3\n",
    "\n",
    "for i in range(50):\n",
    "    #print(generate_str)\n",
    "    next_words = n.next_word([prev_word1, prev_word2, prev_word3],  Words4,4)\n",
    "    prev_word1 = prev_word2\n",
    "    prev_word2 = prev_word3\n",
    "    prev_word3 = next_words\n",
    "    generate_str = generate_str+\" \"+ next_words\n",
    "print(generate_str.replace(\"NEWLINE \",\"\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'THE TINGLING NEWLINE'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prev_word1 = \"S\"#words_by_syllables[2][random.randint(0,len(words_by_syllables[3]))]\n",
    "temp       = list(Words4[prev_word1].keys())\n",
    "prev_word2 = temp[random.randint(0,len(temp)-1)]\n",
    "temp2      = list(Words4[prev_word1][prev_word2].keys())\n",
    "prev_word3 = temp2[random.randint(0,len(temp2)-1)]\n",
    "generate_str = prev_word1+\" \"+prev_word2 + \" \" +prev_word3\n",
    "generate_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'KNOW': 71,\n",
       " 'SPEAK': 1,\n",
       " 'JUDGE': 1,\n",
       " 'FEEL': 6,\n",
       " 'THINK': 14,\n",
       " 'CONTRADICT': 1,\n",
       " 'BLAME': 1,\n",
       " 'WANT': 21,\n",
       " 'RIDE': 1,\n",
       " 'BELIEVE': 10,\n",
       " 'DESERVE': 1,\n",
       " 'LIKE': 7,\n",
       " 'OFFER': 2,\n",
       " 'REMEMBER': 5,\n",
       " 'SHARE': 1,\n",
       " 'HOPE': 1,\n",
       " 'CALL': 2,\n",
       " 'EXPECT': 1,\n",
       " 'WAIT': 1,\n",
       " 'SAY': 2,\n",
       " 'WASTE': 1,\n",
       " 'HEAR': 3,\n",
       " 'HAVE': 7,\n",
       " 'MENTION': 2,\n",
       " 'ENVY': 1,\n",
       " 'DIE': 1,\n",
       " 'GO': 3,\n",
       " 'CARE': 6,\n",
       " 'EVEN': 1,\n",
       " 'UNDERSTAND': 8,\n",
       " 'NEWLINE': 6,\n",
       " 'LABOR': 1,\n",
       " 'HATE': 1,\n",
       " 'LOVE': 5,\n",
       " 'INTEND': 1,\n",
       " 'MEAN': 6,\n",
       " 'ANSWER': 1,\n",
       " 'VALUE': 1,\n",
       " 'FEAR': 2,\n",
       " 'ACCUSE': 1,\n",
       " 'FETISHIZE': 1,\n",
       " 'ASK': 4,\n",
       " 'ATONE': 1,\n",
       " 'SEE': 5,\n",
       " 'LOOK': 2,\n",
       " 'YET': 1,\n",
       " 'DRINK': 1,\n",
       " 'EXIST': 3,\n",
       " 'KNOWAND': 1,\n",
       " 'FEARTHAT': 1,\n",
       " 'SLEEP': 1,\n",
       " 'APOLOGIZETO': 1,\n",
       " 'RECALL': 2,\n",
       " 'BOAST': 1,\n",
       " 'FIND': 3,\n",
       " 'LONG': 1,\n",
       " 'MOCK': 1,\n",
       " 'AVERT': 1,\n",
       " 'LEAVE': 1,\n",
       " 'DARE': 1,\n",
       " 'MIND': 1,\n",
       " 'HEED': 1,\n",
       " 'RAGE': 1,\n",
       " 'FREELY': 1,\n",
       " 'BID': 1,\n",
       " 'CONSENT': 1,\n",
       " 'QUESTION': 1,\n",
       " 'DOUBT': 1,\n",
       " 'EASILY': 1,\n",
       " 'EAT': 1,\n",
       " 'COME': 1,\n",
       " 'DELIGHT': 1,\n",
       " 'GATHER': 1,\n",
       " 'DROWN': 1,\n",
       " '”': 1,\n",
       " 'TASTE': 1,\n",
       " 'TREMBLE': 1,\n",
       " 'USE': 1,\n",
       " 'PITY': 1,\n",
       " 'APOLOGIZE': 1,\n",
       " 'OFTEN': 1,\n",
       " 'SACK': 1,\n",
       " 'DENY': 1,\n",
       " 'ATTEMPT': 1,\n",
       " 'WRITE': 1,\n",
       " '!': 1,\n",
       " 'TAKE': 1,\n",
       " 'MIX': 1,\n",
       " 'DWELL': 1,\n",
       " 'STRIVE': 1,\n",
       " 'WEEP': 1,\n",
       " 'TALK': 1,\n",
       " 'STOP': 1,\n",
       " 'LAUGH': 1,\n",
       " 'SNIVEL': 1,\n",
       " 'TROUBLE': 1,\n",
       " 'DECLINE': 1,\n",
       " 'PRESS': 1,\n",
       " 'GIVE': 1,\n",
       " 'DESPISE': 1,\n",
       " 'FAIL': 1,\n",
       " 'ERR': 1,\n",
       " 'NOT': 1,\n",
       " 'STEP': 1,\n",
       " 'WISH': 1,\n",
       " 'SING': 1}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Words4[\"I\"][\"DO\"][\"NOT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
